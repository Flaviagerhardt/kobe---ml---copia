import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import mlflow
import os
import plotly.express as px
import plotly.graph_objects as go
from mlflow.tracking import MlflowClient

# Configurar p√°gina
st.set_page_config(
    page_title="Dashboard de Monitoramento - Kobe Bryant Shots",
    page_icon="üèÄ",
    layout="wide"
)

# T√≠tulo da aplica√ß√£o
st.title("üìä Dashboard de Monitoramento do Modelo")
st.markdown("### Previs√£o de Arremessos de Kobe Bryant")

# Sidebar para navega√ß√£o
st.sidebar.title("Navega√ß√£o")
page = st.sidebar.radio("Ir para", ["Vis√£o Geral", "Desempenho do Modelo", "Monitoramento de Produ√ß√£o", "Distribui√ß√£o de Dados"])

# Configurar o cliente MLflow
mlflow_tracking_uri = "mlruns"
os.environ["MLFLOW_TRACKING_URI"] = mlflow_tracking_uri
client = MlflowClient(tracking_uri=mlflow_tracking_uri)

# Fun√ß√£o para carregar dados
@st.cache_data
def carregar_dados():
    try:
        # Carregar dados de treinamento, teste e produ√ß√£o
        train = pd.read_parquet("data/05_model_input/base_train.parquet")
        test = pd.read_parquet("data/05_model_input/base_test.parquet")
        prod = pd.read_parquet("data/01_raw/dataset_kobe_prod.parquet")
        
        # Carregar previs√µes
        try:
            predicoes = pd.read_parquet("data/07_model_output/predicoes.parquet")
        except:
            predicoes = None
            
        return train, test, prod, predicoes
    except Exception as e:
        st.error(f"Erro ao carregar dados: {e}")
        return None, None, None, None

# Fun√ß√£o para obter m√©tricas do MLflow
@st.cache_data
def obter_metricas_mlflow():
    try:
        # Obter experimentos
        experimentos = client.search_experiments()
        
        # Obter todas as rodadas
        runs = []
        for exp in experimentos:
            exp_runs = client.search_runs(experiment_ids=[exp.experiment_id])
            runs.extend(exp_runs)
        
        # Organizar m√©tricas
        metricas = []
        for run in runs:
            if run.data.metrics:
                metricas.append({
                    "run_id": run.info.run_id,
                    "run_name": run.data.tags.get("mlflow.runName", "Unknown"),
                    "status": run.info.status,
                    "metrics": run.data.metrics,
                    "start_time": run.info.start_time,
                    "end_time": run.info.end_time
                })
        
        return metricas
    except Exception as e:
        st.error(f"Erro ao obter m√©tricas do MLflow: {e}")
        return []

# Carregar dados
train, test, prod, predicoes = carregar_dados()
metricas_mlflow = obter_metricas_mlflow()

# P√°gina de Vis√£o Geral
if page == "Vis√£o Geral":
    st.header("Vis√£o Geral do Projeto")
    
    # Informa√ß√µes do dataset
    col1, col2, col3 = st.columns(3)
    
    if train is not None and test is not None:
        col1.metric("Tamanho do Conjunto de Treinamento", f"{len(train)}")
        col2.metric("Tamanho do Conjunto de Teste", f"{len(test)}")
        col3.metric("Tamanho do Conjunto de Produ√ß√£o", f"{len(prod) if prod is not None else 'N/A'}")
        
        # Distribui√ß√£o das classes
        st.subheader("Distribui√ß√£o da Vari√°vel Alvo (shot_made_flag)")
        
        fig = plt.figure(figsize=(10, 6))
        ax = fig.add_subplot(111)
        train_counts = train["shot_made_flag"].value_counts(normalize=True) * 100
        test_counts = test["shot_made_flag"].value_counts(normalize=True) * 100
        
        x = np.arange(2)
        width = 0.35
        
        ax.bar(x - width/2, [train_counts.get(0, 0), train_counts.get(1, 0)], width, label='Treino')
        ax.bar(x + width/2, [test_counts.get(0, 0), test_counts.get(1, 0)], width, label='Teste')
        
        ax.set_xticks(x)
        ax.set_xticklabels(['Errou (0)', 'Acertou (1)'])
        ax.set_ylabel('Porcentagem (%)')
        ax.set_title('Distribui√ß√£o da Vari√°vel Alvo nos Conjuntos de Dados')
        ax.legend()
        
        st.pyplot(fig)
        
        # Mapa de calor de correla√ß√£o
        st.subheader("Correla√ß√£o entre Vari√°veis")
        
        fig = plt.figure(figsize=(10, 8))
        corr = train.corr()
        sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
        plt.title("Mapa de Calor de Correla√ß√£o")
        
        st.pyplot(fig)
    else:
        st.warning("N√£o foi poss√≠vel carregar os dados de treinamento e teste.")

# P√°gina de Desempenho do Modelo
elif page == "Desempenho do Modelo":
    st.header("Desempenho dos Modelos")
    
    # Exibir m√©tricas do MLflow
    if metricas_mlflow:
        # Filtrar apenas runs de treinamento
        runs_treinamento = [m for m in metricas_mlflow if "Treinamento" in m.get("run_name", "")]
        
        if runs_treinamento:
            # Compara√ß√£o de log loss
            log_loss_data = []
            f1_data = []
            
            for run in runs_treinamento:
                modelo = run["run_name"].replace("Treinamento_", "")
                
                if "log_loss" in run["metrics"]:
                    log_loss_data.append({
                        "Modelo": modelo,
                        "Log Loss": run["metrics"]["log_loss"]
                    })
                
                if "f1_score" in run["metrics"]:
                    f1_data.append({
                        "Modelo": modelo,
                        "F1 Score": run["metrics"]["f1_score"]
                    })
            
            # Gr√°ficos de m√©tricas
            col1, col2 = st.columns(2)
            
            with col1:
                if log_loss_data:
                    st.subheader("Log Loss por Modelo")
                    df_log_loss = pd.DataFrame(log_loss_data)
                    fig = px.bar(df_log_loss, x="Modelo", y="Log Loss", 
                                color="Modelo", title="Log Loss (menor √© melhor)")
                    st.plotly_chart(fig)
                
            with col2:
                if f1_data:
                    st.subheader("F1 Score por Modelo")
                    df_f1 = pd.DataFrame(f1_data)
                    fig = px.bar(df_f1, x="Modelo", y="F1 Score", 
                                color="Modelo", title="F1 Score (maior √© melhor)")
                    st.plotly_chart(fig)
        else:
            st.warning("N√£o foram encontradas rodadas de treinamento nos logs do MLflow.")
    else:
        st.warning("N√£o foi poss√≠vel obter m√©tricas do MLflow.")

# P√°gina de Monitoramento de Produ√ß√£o
elif page == "Monitoramento de Produ√ß√£o":
    st.header("Monitoramento em Produ√ß√£o")
    
    if predicoes is not None:
        # Distribui√ß√£o das previs√µes
        st.subheader("Distribui√ß√£o das Previs√µes")
        
        # Histograma de probabilidades preditas
        fig = px.histogram(predicoes, x="shot_made_flag_prob", 
                          title="Distribui√ß√£o das Probabilidades Preditas",
                          labels={"shot_made_flag_prob": "Probabilidade Predita"})
        st.plotly_chart(fig)
        
        # Se tiver a vari√°vel alvo real nos dados de produ√ß√£o
        if "shot_made_flag" in predicoes.columns:
            st.subheader("Compara√ß√£o: Valores Reais vs. Preditos")
            
            # Matriz de confus√£o
            conf_matrix = pd.crosstab(predicoes["shot_made_flag"], 
                                     predicoes["shot_made_flag_pred"], 
                                     rownames=['Real'], 
                                     colnames=['Predito'])
            
            fig = px.imshow(conf_matrix, 
                           text_auto=True, 
                           color_continuous_scale='Blues',
                           title="Matriz de Confus√£o")
            st.plotly_chart(fig)
            
            # Curva ROC
            from sklearn.metrics import roc_curve, auc
            fpr, tpr, _ = roc_curve(predicoes["shot_made_flag"], predicoes["shot_made_flag_prob"])
            roc_auc = auc(fpr, tpr)
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=fpr, y=tpr, name=f'ROC curve (AUC = {roc_auc:.3f})'))
            fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Random', line=dict(dash='dash')))
            fig.update_layout(
                title='Curva ROC',
                xaxis_title='Taxa de Falsos Positivos',
                yaxis_title='Taxa de Verdadeiros Positivos'
            )
            st.plotly_chart(fig)
            
            # M√©tricas de desempenho em produ√ß√£o
            col1, col2 = st.columns(2)
            
            # Obter m√©tricas de produ√ß√£o dos logs do MLflow
            prod_metrics = None
            for m in metricas_mlflow:
                if "PipelineAplicacao" in m.get("run_name", ""):
                    prod_metrics = m["metrics"]
                    break
            
            if prod_metrics:
                if "log_loss_producao" in prod_metrics:
                    col1.metric("Log Loss em Produ√ß√£o", f"{prod_metrics['log_loss_producao']:.4f}")
                if "f1_score_producao" in prod_metrics:
                    col2.metric("F1 Score em Produ√ß√£o", f"{prod_metrics['f1_score_producao']:.4f}")
        else:
            st.info("N√£o h√° valores reais dispon√≠veis para compara√ß√£o no conjunto de produ√ß√£o.")
    else:
        st.warning("Os dados de previs√£o n√£o est√£o dispon√≠veis.")

# P√°gina de Distribui√ß√£o de Dados
elif page == "Distribui√ß√£o de Dados":
    st.header("Distribui√ß√£o de Dados")
    
    if train is not None and prod is not None:
        # Selecionar vari√°vel para visualizar
        features = ["lat", "lng", "minutes_remaining", "period", "playoffs", "shot_distance"]
        feature = st.selectbox("Selecionar vari√°vel para visualizar", features)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader(f"Distribui√ß√£o em Treino - {feature}")
            fig = px.histogram(train, x=feature, color="shot_made_flag", 
                              barmode="overlay", histnorm="percent",
                              labels={"shot_made_flag": "Acertou"})
            st.plotly_chart(fig)
        
        with col2:
            st.subheader(f"Distribui√ß√£o em Produ√ß√£o - {feature}")
            
            # Se tiver shot_made_flag em prod
            if "shot_made_flag" in prod.columns:
                fig = px.histogram(prod, x=feature, color="shot_made_flag", 
                                  barmode="overlay", histnorm="percent",
                                  labels={"shot_made_flag": "Acertou"})
            else:
                fig = px.histogram(prod, x=feature, histnorm="percent")
            
            st.plotly_chart(fig)
        
        # Verificar drift (mudan√ßa na distribui√ß√£o)
        st.subheader("An√°lise de Data Drift")
        
        # Calcular estat√≠sticas para compara√ß√£o
        train_stats = train[feature].describe()
        prod_stats = prod[feature].describe()
        
        # Criar df com estat√≠sticas lado a lado
        stats_df = pd.DataFrame({
            "Estat√≠stica": train_stats.index,
            "Treinamento": train_stats.values,
            "Produ√ß√£o": prod_stats.values,
            "Diferen√ßa (%)": ((prod_stats.values - train_stats.values) / train_stats.values * 100)
        })
        
        # Destacar diferen√ßas significativas
        def highlight_drift(val):
            if isinstance(val, float) and abs(val) > 10:
                return 'background-color: yellow'
            return ''
        
        st.dataframe(stats_df.style.applymap(highlight_drift, subset=['Diferen√ßa (%)']))
        
        # Mostrar an√°lise de drift do MLflow
        st.subheader("An√°lise de Drift Global")
        
        # Obter logs de an√°lise de drift
        drift_runs = [m for m in metricas_mlflow if "AnaliseDrift" in m.get("run_name", "")]
        
        if drift_runs:
            latest_drift = drift_runs[-1]["metrics"]
            
            # Mostrar features com drift
            features_with_drift = []
            for feature in features:
                if f"has_drift_{feature}" in latest_drift and latest_drift[f"has_drift_{feature}"] == 1:
                    features_with_drift.append({
                        "Feature": feature, 
                        "p-value": latest_drift.get(f"p_value_{feature}", 0),
                        "Diferen√ßa M√©dia (%)": latest_drift.get(f"mean_diff_pct_{feature}", 0)
                    })
            
            if features_with_drift:
                st.warning(f"Foram detectados drifts em {len(features_with_drift)} features!")
                st.dataframe(pd.DataFrame(features_with_drift))
            else:
                st.success("N√£o foram detectados drifts significativos nas features!")
            
            # Mostrar m√©tricas globais
            col1, col2 = st.columns(2)
            col1.metric("Features com Drift", f"{int(latest_drift.get('features_with_drift', 0))}/{len(features)}")
            col2.metric("Percentual de Drift", f"{latest_drift.get('drift_percentage', 0):.1f}%")
            
            if "significant_drift" in latest_drift and latest_drift["significant_drift"] == 1:
                st.error("Foi detectado um drift significativo global! Recomenda-se retreinar o modelo.")
            else:
                st.info("N√£o foi detectado drift significativo global. O modelo mant√©m sua validade.")
        else:
            st.info("N√£o foram encontrados registros de an√°lise de drift no MLflow.")
    else:
        st.warning("N√£o foi poss√≠vel carregar os dados de treinamento e produ√ß√£o.")

# Informa√ß√µes adicionais no rodap√©
st.markdown("---")
st.markdown("**Dashboard de Monitoramento do Projeto de ML - Arremessos do Kobe Bryant**")
st.markdown("Desenvolvido como parte do Projeto de Disciplina de Engenharia de Machine Learning")